{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality Sensitive Hashing\n",
    "(by Tevfik Aytekin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Nearest Neighbor\n",
    "\n",
    "Finding nearest neighbors in a set of objects is a very general problem which has applications in many areas. If the size of the set of objects is very large then an exhaustive pairwise comparision of all ojects can be very costly.\n",
    "\n",
    "**Randomized near-neighbor reporting:** Given a set $P$ of points in a $d$-dimensional space $\\mathbb{R}^d$, and parameters $R > 0, > δ > 0$, construct a data structure which, given any query point $q$, reports each $R$-near neighbor of $q$ in $P$ with probability $1 − δ$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main idea of LSH\n",
    "\n",
    "The main idea of LSH is to design hash functions such that the probability of a collision is much higher for closer points compared to points which are far apart. Given such hash functions one can hash a query point and retrive the elements in the buckets that contain the query point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal Definition of LSH \n",
    "(following definition and figure is taken from [mmds book](http://www.mmds.org/) where you can read more about LSH)\n",
    "\n",
    "Let $d_1 < d_2$ be two distances according to some distance measure $d$. A family $F$ of functions is said to be $(d_1, d_2, p_1, p_2)-sensitive$ if for every $f$ in $F$:\n",
    "1. If $d(x,y) ≤ d_1$, then the probability that $f(x) = f(y)$ is at least $p_1$. \n",
    "2. If $d(x,y) ≥ d_2$, then the probability that $f(x) = f(y)$ is at most $p_2$.\n",
    "\n",
    "In order for a LSH family to be useful: $p_1 > p_2$.\n",
    "\n",
    "<img src=\"images/lsh.png\" width = \"400\">\n",
    "\n",
    "Once you have a family $F$ of functions we can amplify the gap between the $p_1$ and $p_2$ by AND and OR constructions. \n",
    "\n",
    "Suppose we are given a $(d_1, d_2, p_1, p_2)-sensitive$ family $F$. We can make an AND construction by building $g=(f_1,f_2,...,f_k)$ by choosing $k$ functions at random from $F$. We say that $g(x) = g(y)$ iff $g_i(x) = g_i(y)$ for all $i = 1, 2, . . . , k$.\n",
    "\n",
    "We can make OR constructions by building $h=(g_1,f_2,...,g_l)$ by choosing $l$ functions from the set of $g$ functions as defined above. at random from $F$. Note that all the $f_i$'s in each $g_j$ are choosen at random from $F$. We define $h(x) = h(y)$ iff $g_i(x) = g_i(y)$ for one or more values of $i$. \n",
    "\n",
    "We assume a seperate hash table for each $g_i$. We will insert every point $p$ by the key $q_i(p)$ into each bucket of $g_i$'s during the build phase of LSH. When a query point $q$ comes we will return the elemements in the buckets at each $g_i(q)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An LSH Function for Cosine Similarity\n",
    "\n",
    "For every distance metric (such as cosine, Jaccard, hamming, etc.) you should define a LSH family of hash functions (note that for some distance metrics this may not be possible). For cosine distance sign of the dot product of the data point with a random unit vector is used for construction the LSH. Each such random unit vector constitutes a different function in the LSH family F. The following figure illustrates why dot product with a random unit vector can be used to build an LSH family of function for cosine distance. \n",
    "\n",
    "<img src=\"images/lsh_cosine.jpg\" width = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above equation, $r$ is the random unit vector, $sign(r.a)$ is the sign of the dot product of $r$ and $a$. The equation gives the probability of the sign of the dot product of $r$ witg vectors $a$ and $b$. The figure above can be used for the proof. The arcs show the regions of $r$ where the dot product with $a$ or $b$ is positive. If $r$ is in the insersecting region $(180-\\alpha)$ of the arcs then the signs will be the same. Hence we can conclude that the probability of this to happen is $\\frac{180-\\alpha}{180}$\n",
    "\n",
    "But why show that we can build LSH family for cosine? Because as the distance two vectors decreases (or equivalently as $\\alpha$ decreases) the probability of a collusion increases, i.e., similar vectors have a higher probability of being mapped to the same hash bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import itertools\n",
    "import pandas as pd\n",
    "#from tabulate import tabulate\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measurement\n",
    "\n",
    "Nearest neighbor search: Suppose that we have a large dataset of vectors X and given a target vector we want to find the most similar k vectors to the target vector in the dataset X. Note that we can do this type of search more than once. \n",
    "\n",
    "First let us generate the dataset X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vectors = 100000\n",
    "dim = 10\n",
    "n_neighbors = 100\n",
    "n_queries = 2000\n",
    "\n",
    "target_vectors = np.random.randn(n_queries, dim)\n",
    "dataset = np.random.randn(n_vectors, dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive search implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSearch:\n",
    "    def __init__(self, data):\n",
    "        # data is a n-by-d matrix where d is the length of the vectors\n",
    "        # and n is the number of vectors. \n",
    "        self.data = data\n",
    "        self.norms = None\n",
    "        self.data_normalized_T = None\n",
    "    \n",
    "        \n",
    "    def build(self):\n",
    "        self.norms = np.linalg.norm(self.data, axis=1)\n",
    "        self.norms.shape = (len(self.norms), 1)\n",
    "        \n",
    "        data_normalized = np.divide(self.data, self.norms)\n",
    "        self.data_normalized_T = data_normalized.T\n",
    "            \n",
    "            \n",
    "    def find_nn(self, target_vector, n_neighbors=10):\n",
    "\n",
    "        #target_vector_normalized = np.linalg.norm(target_vector)\n",
    "        \n",
    "        sims = np.dot(target_vector,self.data_normalized_T)[0]\n",
    "        return sims.argsort()[::-1][:n_neighbors]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSH Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, data):\n",
    "        # data is a n-by-d matrix where d is the length of the vectors\n",
    "        # and n is the number of vectors. \n",
    "        self.data = data\n",
    "        self.bands = []\n",
    "        self.random_vectors = []\n",
    "    \n",
    "    def build(self, n_random_vectors, n_bands = 1):\n",
    "        for b in range(n_bands):\n",
    "            # generate random vectors\n",
    "            self.bands.append({})\n",
    "            dim = self.data.shape[1]\n",
    "            self.random_vectors.append(np.random.randn(n_random_vectors, dim))\n",
    "            # generate dim-by-n index bits\n",
    "            sign_bits = np.dot(self.data, self.random_vectors[b].T) >= 0\n",
    "            n_data_vectors = self.data.shape[0]\n",
    "            for i in range(n_data_vectors):\n",
    "                key = tuple(sign_bits[i,:])\n",
    "                if key not in self.bands[b]:\n",
    "                    self.bands[b][key] = []\n",
    "                self.bands[b][key].append(i)\n",
    "            \n",
    "            \n",
    "    def find_nn(self, target_vector, n_neighbors=10, n_bands = 1):\n",
    "\n",
    "        candidate_ids = []\n",
    "        for b in range(n_bands):\n",
    "            sign_bits = (np.dot(target_vector, self.random_vectors[b].T) >= 0).flatten()\n",
    "            sign_bits_tuple = tuple(sign_bits)\n",
    "            ids = self.bands[b].get(sign_bits_tuple)\n",
    "            if ids is None: \n",
    "                ids = []\n",
    "            candidate_ids = candidate_ids + ids\n",
    "        if len(candidate_ids) > 0:\n",
    "                candidate_vectors = self.data[candidate_ids, :]\n",
    "                sims = 1 - pairwise_distances(target_vector, candidate_vectors, metric='cosine').flatten()\n",
    "                sorted_nn = sims.argsort()[::-1]\n",
    "                return np.array([candidate_ids[i] for i in sorted_nn])\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive search experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:18830.849170684814ms\n"
     ]
    }
   ],
   "source": [
    "ns = NaiveSearch(dataset)\n",
    "ns.build()\n",
    "tic = time.time()\n",
    "ns_nn = []\n",
    "for i in range(n_queries):\n",
    "    target_vector = target_vectors[i,:].reshape(1,dim)\n",
    "    neighbors = ns.find_nn(target_vector, n_neighbors)\n",
    "    ns_nn.append(neighbors)\n",
    "toc = time.time()\n",
    "print(\"Time:\"+str(1000*(toc-tic))+\"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSH experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022.993</td>\n",
       "      <td>1713.669</td>\n",
       "      <td>707.523</td>\n",
       "      <td>1437.860</td>\n",
       "      <td>701.669</td>\n",
       "      <td>648.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2838.700</td>\n",
       "      <td>2146.831</td>\n",
       "      <td>2238.163</td>\n",
       "      <td>1800.231</td>\n",
       "      <td>1177.027</td>\n",
       "      <td>718.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3513.459</td>\n",
       "      <td>2476.791</td>\n",
       "      <td>2243.993</td>\n",
       "      <td>2122.423</td>\n",
       "      <td>1222.424</td>\n",
       "      <td>1253.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4050.672</td>\n",
       "      <td>3228.182</td>\n",
       "      <td>2584.521</td>\n",
       "      <td>2415.643</td>\n",
       "      <td>1979.427</td>\n",
       "      <td>1767.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5481.961</td>\n",
       "      <td>3497.943</td>\n",
       "      <td>2768.884</td>\n",
       "      <td>2433.868</td>\n",
       "      <td>2037.536</td>\n",
       "      <td>1828.738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         10        11        12        13        14        15\n",
       "1  2022.993  1713.669   707.523  1437.860   701.669   648.546\n",
       "2  2838.700  2146.831  2238.163  1800.231  1177.027   718.645\n",
       "3  3513.459  2476.791  2243.993  2122.423  1222.424  1253.547\n",
       "4  4050.672  3228.182  2584.521  2415.643  1979.427  1767.620\n",
       "5  5481.961  3497.943  2768.884  2433.868  2037.536  1828.738"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.153875</td>\n",
       "      <td>0.13133</td>\n",
       "      <td>0.098420</td>\n",
       "      <td>0.090055</td>\n",
       "      <td>0.072275</td>\n",
       "      <td>0.061560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280490</td>\n",
       "      <td>0.23738</td>\n",
       "      <td>0.222780</td>\n",
       "      <td>0.174685</td>\n",
       "      <td>0.149720</td>\n",
       "      <td>0.112995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.391555</td>\n",
       "      <td>0.31869</td>\n",
       "      <td>0.280935</td>\n",
       "      <td>0.251775</td>\n",
       "      <td>0.195735</td>\n",
       "      <td>0.170245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.470985</td>\n",
       "      <td>0.41082</td>\n",
       "      <td>0.354310</td>\n",
       "      <td>0.320825</td>\n",
       "      <td>0.256580</td>\n",
       "      <td>0.226115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.532780</td>\n",
       "      <td>0.46472</td>\n",
       "      <td>0.415255</td>\n",
       "      <td>0.364320</td>\n",
       "      <td>0.313465</td>\n",
       "      <td>0.273500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         10       11        12        13        14        15\n",
       "1  0.153875  0.13133  0.098420  0.090055  0.072275  0.061560\n",
       "2  0.280490  0.23738  0.222780  0.174685  0.149720  0.112995\n",
       "3  0.391555  0.31869  0.280935  0.251775  0.195735  0.170245\n",
       "4  0.470985  0.41082  0.354310  0.320825  0.256580  0.226115\n",
       "5  0.532780  0.46472  0.415255  0.364320  0.313465  0.273500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Neighbor Size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>428.4710</td>\n",
       "      <td>293.6910</td>\n",
       "      <td>139.6125</td>\n",
       "      <td>158.6980</td>\n",
       "      <td>87.5080</td>\n",
       "      <td>59.4100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>921.1010</td>\n",
       "      <td>560.0285</td>\n",
       "      <td>571.2040</td>\n",
       "      <td>336.8825</td>\n",
       "      <td>217.2575</td>\n",
       "      <td>113.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1294.1335</td>\n",
       "      <td>665.7940</td>\n",
       "      <td>578.3915</td>\n",
       "      <td>510.7150</td>\n",
       "      <td>216.3365</td>\n",
       "      <td>186.2635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1571.9305</td>\n",
       "      <td>1131.0075</td>\n",
       "      <td>745.8560</td>\n",
       "      <td>672.2815</td>\n",
       "      <td>375.5255</td>\n",
       "      <td>278.4880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2120.0165</td>\n",
       "      <td>1285.0700</td>\n",
       "      <td>871.5905</td>\n",
       "      <td>691.1835</td>\n",
       "      <td>465.3785</td>\n",
       "      <td>345.8395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          10         11        12        13        14        15\n",
       "1   428.4710   293.6910  139.6125  158.6980   87.5080   59.4100\n",
       "2   921.1010   560.0285  571.2040  336.8825  217.2575  113.0610\n",
       "3  1294.1335   665.7940  578.3915  510.7150  216.3365  186.2635\n",
       "4  1571.9305  1131.0075  745.8560  672.2815  375.5255  278.4880\n",
       "5  2120.0165  1285.0700  871.5905  691.1835  465.3785  345.8395"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#target_vector_b = target_vector\n",
    "#print(neighbors)\n",
    "min_n_random_vectors = 10\n",
    "max_n_random_vectors = 15\n",
    "max_n_bands = 5\n",
    "\n",
    "elapsed_time = np.zeros((max_n_bands, (max_n_random_vectors-min_n_random_vectors)+1))\n",
    "recall = np.zeros((max_n_bands, (max_n_random_vectors-min_n_random_vectors)+1))\n",
    "avg_neigbor_size = np.zeros((max_n_bands, (max_n_random_vectors-min_n_random_vectors)+1))\n",
    "\n",
    "for b in range(1, max_n_bands+1):\n",
    "    for v in range(min_n_random_vectors,max_n_random_vectors+1):\n",
    "        lsh_nn = []\n",
    "        lsh = LSH(dataset)\n",
    "        lsh.build(v, n_bands = b)\n",
    "        tic = time.process_time()\n",
    "        for i in range(n_queries):\n",
    "            target_vector = target_vectors[i,:].reshape(1,dim)\n",
    "            neighbors = lsh.find_nn(target_vector, n_neighbors, n_bands = b)\n",
    "            lsh_nn.append(neighbors)\n",
    "        toc = time.process_time()\n",
    "        #print(b-1,v-min_n_random_vectors)\n",
    "        #print(v)\n",
    "        elapsed_time[b-1,v-min_n_random_vectors] = (toc-tic)*1000\n",
    "        true_positives = sum([len(np.intersect1d(ns_nn[i], lsh_nn[i][:n_neighbors])) for i in range(n_queries)])\n",
    "        recall[b-1,v-min_n_random_vectors] = true_positives / (n_queries*n_neighbors)\n",
    "        avg_neigbor_size[b-1,v-min_n_random_vectors] = len(list(itertools.chain(*lsh_nn)))/n_queries\n",
    "    \n",
    "\n",
    "\n",
    "#pd.DataFrame({\"Number of Random Vectors:\": range(min_n_random_vectors,max_n_random_vectors+1), \"Elapsed Time\":elapsed_time, \"Recall\": recall, \"Avg. Neighbor Size\": avg_neigbor_size}) \n",
    "elapsed_time_df = pd.DataFrame(elapsed_time)\n",
    "recall_df = pd.DataFrame(recall)\n",
    "avg_neigbor_size_df = pd.DataFrame(avg_neigbor_size)\n",
    "\n",
    "row_names = [str(i) for i in range(1, max_n_bands+1)]\n",
    "column_names = [str(i) for i in range(min_n_random_vectors, max_n_random_vectors+1)]\n",
    "elapsed_time_df.columns = recall_df.columns = avg_neigbor_size_df.columns = column_names\n",
    "elapsed_time_df.index = recall_df.index = avg_neigbor_size_df.index = row_names\n",
    "print(\"Elapsed Time\")\n",
    "display(elapsed_time_df)\n",
    "print(\"Recall\")\n",
    "display(recall_df)\n",
    "print(\"Avg. Neighbor Size\")\n",
    "display(avg_neigbor_size_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sense of the cost of pairwise similarity computation\n",
    "\n",
    "Suppose that we have n objects represented as vectors of size d. The cost of computing all pairwise similarities is $O(n^2d)$. When $n$ is large the cost of this computation can be quite large. And in some applications like finding near duplicate web pages, in order to eliminate them from search results, $n$ (number of web pages) can be really large.\n",
    "\n",
    "To get a sense of this cost below is a simple code which measures the time two multiply two matrices of size $n$-by-$d$. (Note that some version of multiplication is needed in order to find similarities between the vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:4142.167ms\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "d = 1000\n",
    "X = np.random.randn(n,d)\n",
    "tic = time.process_time()\n",
    "\n",
    "z = np.dot(X,X.T)\n",
    "\n",
    "toc = time.process_time()\n",
    "print(\"Time:\"+str(1000*(toc-tic))+\"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the time complexity is quadratic, we expect the figures in the following table if we increase $n$. You can try some larger $n$'s to test this.\n",
    "\n",
    "|  n | time  | \n",
    "|:---|:---|\n",
    "|  100k | 400 seconds  |\n",
    "|  1m | 11 hours  |\n",
    "|  10m | 46 days  |\n",
    "|  100m | 12 years  |\n",
    "|  1b | 12 centuries |\n",
    "\n",
    "The above results are taken on a 2,3 GHz Dual-Core Intel Core i5 laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
