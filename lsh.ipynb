{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality Sensitive Hashing\n",
    "(by Tevfik Aytekin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Nearest Neighbor\n",
    "\n",
    "Finding nearest neighbors in a set of objects is a very general problem which has applications in many areas. If the size of the set of objects is very large then an exhaustive pairwise comparision of all ojects can be very costly.\n",
    "\n",
    "**Randomized near-neighbor reporting:** Given a set $P$ of points in a $d$-dimensional space $\\mathbb{R}^d$, and parameters $R > 0, > δ > 0$, construct a data structure which, given any query point $q$, reports each $R$-near neighbor of $q$ in $P$ with probability $1 − δ$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main idea of LSH\n",
    "\n",
    "The main idea of LSH is to design hash functions such that the probability of a collision is much higher for closer points compared to points which are far apart. Given such hash functions one can hash a query point and retrive the elements in the buckets that contain the query point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An LSH Function for Cosine Similarity\n",
    "\n",
    "<img src=\"images/lsh_cosine.jpg\" width = \"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measurement\n",
    "\n",
    "Nearest neighbor search: Suppose that we have a large dataset of vectors X and given a target vector we want to find the most similar k vectors to the target vector in the dataset X. Note that we can do this type of search more than once. \n",
    "\n",
    "First let us generate the dataset X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:20857.75399208069ms\n",
      "Time:596.580982208252ms\n",
      "Hit ratio:  0.023155\n"
     ]
    }
   ],
   "source": [
    "n_vectors = 100000\n",
    "dim = 10\n",
    "n_neighbors = 100\n",
    "n_queries = 2000\n",
    "n_random_vectors = 20\n",
    "\n",
    "target_vectors = np.random.randn(n_queries, dim)\n",
    "dataset = np.random.randn(n_vectors, dim)\n",
    "ns = NaiveSearch(dataset)\n",
    "ns.build()\n",
    "ns_nn = []\n",
    "tic = time.time()\n",
    "for i in range(n_queries):\n",
    "    target_vector = target_vectors[i,:].reshape(1,dim)\n",
    "    neighbors = ns.find_nn(target_vector, n_neighbors)\n",
    "    ns_nn.append(neighbors)\n",
    "#target_vector_b = target_vector\n",
    "#print(neighbors)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Time:\"+str(1000*(toc-tic))+\"ms\")\n",
    "lsh_nn = []\n",
    "\n",
    "lsh = LSH(dataset)\n",
    "lsh.build(n_random_vectors)\n",
    "tic = time.time()\n",
    "for i in range(n_queries):\n",
    "    target_vector = target_vectors[i,:].reshape(1,dim)\n",
    "    neighbors = lsh.find_nn(target_vector, n_neighbors)\n",
    "    lsh_nn.append(neighbors)\n",
    "toc = time.time()\n",
    "print(\"Time:\"+str(1000*(toc-tic))+\"ms\")\n",
    "#target_vector_b = target_vector\n",
    "#print(neighbors)\n",
    "\n",
    "hits = [len(np.intersect1d(ns_nn[i], lsh_nn[i])) for i in range(n_queries)]\n",
    "#print(hits)\n",
    "print(\"Hit ratio: \",sum(hits) / (n_queries*n_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSearch:\n",
    "    def __init__(self, data):\n",
    "        # data is a n-by-d matrix where d is the length of the vectors\n",
    "        # and n is the number of vectors. \n",
    "        self.data = data\n",
    "        self.norms = None\n",
    "        self.data_normalized_T = None\n",
    "    \n",
    "        \n",
    "    def build(self):\n",
    "        self.norms = np.linalg.norm(self.data, axis=1)\n",
    "        self.norms.shape = (len(self.norms), 1)\n",
    "        \n",
    "        data_normalized = np.divide(self.data, self.norms)\n",
    "        self.data_normalized_T = data_normalized.T\n",
    "            \n",
    "            \n",
    "    def find_nn(self, target_vector, n_neighbors=10):\n",
    "\n",
    "        #target_vector_normalized = np.linalg.norm(target_vector)\n",
    "        \n",
    "        sims = np.dot(target_vector,self.data_normalized_T)[0]\n",
    "        return sims.argsort()[::-1][:n_neighbors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSH:\n",
    "    def __init__(self, data):\n",
    "        # data is a n-by-d matrix where d is the length of the vectors\n",
    "        # and n is the number of vectors. \n",
    "        self.data = data\n",
    "        self.hash_table = {}\n",
    "        self.random_vectors = None\n",
    "    \n",
    "    def build(self, n_random_vectors):\n",
    "        # generate random vectors\n",
    "        dim = self.data.shape[1]\n",
    "        self.random_vectors = np.random.randn(n_random_vectors, dim)\n",
    "        # generate dim-by-n index bits\n",
    "        sign_bits = np.dot(self.data, self.random_vectors.T) >= 0\n",
    "        n_data_vectors = self.data.shape[0]\n",
    "        for i in range(n_data_vectors):\n",
    "            key = tuple(sign_bits[i,:])\n",
    "            if key not in self.hash_table:\n",
    "                self.hash_table[key] = []\n",
    "            self.hash_table[key].append(i)\n",
    "            \n",
    "            \n",
    "    def find_nn(self, target_vector, n_neighbors=10, max_radius = 0):\n",
    "\n",
    "        sign_bits = (np.dot(target_vector, self.random_vectors.T) >= 0).flatten()\n",
    "        sign_bits_tuple = tuple(sign_bits)\n",
    "        candidate_ids = self.hash_table.get(sign_bits_tuple)\n",
    "        if candidate_ids is not None:\n",
    "            candidate_vectors = self.data[candidate_ids, :]\n",
    "            sims = 1 - pairwise_distances(target_vector, candidate_vectors, metric='cosine').flatten()\n",
    "            sorted_nn = sims.argsort()[::-1][:n_neighbors]\n",
    "            return np.array([candidate_ids[i] for i in sorted_nn])\n",
    "        else:\n",
    "            return []\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
